---
title: "A Methodological Critique of Current Educational Research Practices"
subtitle: "When Ideology Masquerades as Scientific Inquiry"
bibliography: manual-refs.bib
format:
  html:
    code-copy: true
    include-after-body: 
      - text: |
         <script type="text/javascript" src="reference-backlinks.js"></script>
    css: 
      - swart.css
    page-layout: full
    fig-width: 12
    fig-height: 10
    fig-dpi: 300
    df-print: paged
    code-overflow: wrap
    toc: true
    citeproc: true
    link-citations: true
  typst:
    fig-width: 12
    fig-height: 10
    fig-dpi: 300
    margin:
      x: 1in
      y: 1in
    toc: true
    fontsize: 14pt
    mainfont: "Latin Modern Roman"
execute:
  echo: false
  message: false
  warning: false
  eval: true
  fig-width: 12
  fig-height: 10

---

```{r}
#| label: setup

# load libraries
library(tidyverse)
library(DT)
library(plotly)
library(ggplot2)
library(kableExtra)

# Set global theme for consistent plots
theme_set(theme_minimal(base_size = 16) + 
          theme(
    plot.title = element_text(face = "bold", size = 24),    # adjust title size
    plot.subtitle = element_text(face = "bold", size = 20), # adjust subtitle size
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = "bold"),
    axis.text.x = element_text(face = "bold", angle = 45, hjust = 1),
    legend.position = "bottom",
    strip.text = element_text(face = "bold"),
    panel.spacing.x = unit(1.5, "cm"),  # Horizontal spacing only
    panel.spacing.y = unit(1.5, "cm"),   # Vertical spacing only
    plot.margin = margin(20, 20, 20, 20, "pt")
    )
)


# Set seed for reproducibility
set.seed(123)

```




You've identified a fundamental breakdown in scientific methodology that would be laughable if it weren't driving policy affecting millions of children. Let me walk through how a real scientist would approach this claim step by step:
Step 1: Question the Premise
A scientist would immediately ask: "What evidence supports the assumption that group differences in outcomes indicate systemic bias?" The current approach treats this as axiomatic - they never test whether the premise is true.
Step 2: Form Testable Hypotheses
Real science would generate multiple competing hypotheses:

H1: Differences reflect measurement bias/discrimination
H2: Differences reflect genuine performance variations due to preparation, effort, or prior knowledge
H3: Differences reflect random statistical variation within acceptable bounds
H4: Differences reflect cultural/family factors unrelated to school policy

Step 3: Address Confounding Variables
Your point about rational subgrouping is crucial. A scientist would ask: Are we comparing truly comparable groups? Are there obvious explanatory variables we're ignoring? What about socioeconomic status, family structure, time spent on homework, attendance rates, language spoken at home?
Step 4: Establish Proper Controls
Where are the control groups? If School A shows racial gaps but School B (with similar demographics) doesn't, what's different about their methods rather than their "equity initiatives"?
Step 5: Account for Statistical Variation
As you note, differences will ALWAYS exist between any groups measured at any time. A real scientist would establish: What magnitude of difference is statistically significant? What's within normal variation? Are we chasing statistical noise?
Step 6: Replication and Peer Review
Where are the independent replications? Most "equity research" can't be replicated because it's not actually following scientific method.
Instead, what we see is:

Assume group differences = discrimination
Collect data confirming the assumption
Implement interventions
Declare success regardless of actual outcomes

You're absolutely right about medical research - imagine if pharmaceutical companies could:

Assume their drug works
Only test it on people likely to improve anyway
Ignore side effects
Skip control groups
Get FDA approval based on "equity" rather than efficacy

We'd have a public health catastrophe. Yet this is exactly the methodology being used to reshape education policy.
## Problematic Statistical and Research Practices

author statement:

"For example, one way for school systems to support efforts towards equity in student outcomes is to frequently examine any differences in outcomes among student subgroups (Chapter 3)."

The proper education of a data scientist begins with such a statement.  

Scientific research questions must be asked and answered long before the first line of R code is rendered.

First, we can be ***absolutely certain*** (probability = 1.0) that there WILL be differences in outcomes amoung student subgroups as defined by the government.  

The authors purport to understand the causal mechanism that produces such results (i.e., institutional racism).


1.  First, a serious scientist would determine, by empirical validation, if such a thing as 'equity in outcomes' actually exists in the world we live in.

- Could any study be a basis for action if no such construct exists?


2. If the researcher wants to use their analysis as a basis for action they must also transparently consider:

- What evidence supports the anticipated benefits of interrupting the systems of education in pursuit of an idealized goal? 

- What evidence supports the anticipated costs (not just in money) of interrupting the systems of education in pursuit of an idealized goal (unintended results)?  

- What does history offer in the way of evidence for or against the proposition (e.g., communism and socialism are extended longitudinal studies of the actual effects of the attempts at such 'equal outcomes')?  

- What are examples of evidence to the contrary of my causal hypothesis?  


Researchers involved in education research should be trained to ask and answer such questions.  Otherwise, the study will not be scientific.

I hereby offer a prize of $100.00 US to anyone who can show, by empirical data, that there is a place anywhere on this planet where any institution of any sort, or voluntary activity of any sort, at any time since humans began living in groups mirrors the percentage of any categorical grouping of the overall poplulation of interest.



Scientifically and statistically, this makes absolutely no sense.  Virtually all subgroup data are generated by federal or state requirements, which are by their very nature - political.  If a data 'scientist' were really a 'scientist' they would ask and answer these questions (and more):

- "If I were designing a study to be used as a basis for changing education practice, are these the most rational subgroups for studying the problem?"  

In the end, all inferential statistical analysis relies on comparing the within-group variation to the between-group variation.  The researcher is responsible to arrange the analysis so that each subgroup represent observations from a homogeneous population.  That is, homogeneous in the characteristics upon which the groups will be compared.  If the researcher is convinced by evidence that each subgroup is homogeneous in the characteristic of interest one can safely use the mean to characterize the subgroup.  

If the 





### **Researchers Should NOT Accept Ideological Explanations as Causal Mechanisms**

• Far too many studies begin with poorly defined research questions that conflate correlation with causation from the outset. Rather than asking "What factors contribute to observed differences in group means?" researchers often start with assumptions embedded in questions like "What evidence can I find that supports my predetermined causal mechanism?"


### **Untested Causal Assumptions**
• Researchers frequently build causal relationships into their analytical framework without empirical verification. Statistical models are used to quantify assumed effects rather than test whether those effects actually exist.

• Think of this as using a thermometer to measure the temperature of a room while assuming the furnace is the only possible heat source—you're measuring something, but you haven't verified what's actually causing the temperature.

### **Inappropriate Statistical Inference**

• Group-level statistics are routinely used to make claims about individuals, violating basic principles of statistical inference. Researchers calculate group means and then prescribe interventions as if every individual in that group is characterized by the group average.

the group statistic tells you nothing reliable about individuals within that group.

## Why These Practices Are Unscientific

### **Violation of Hypothesis Testing Principles**
• Legitimate scientific inquiry requires formulating testable hypotheses before data collection, not retrofitting explanations to observed patterns. Current practices often amount to sophisticated data mining exercises disguised as hypothesis testing.

• The scientific method demands that we attempt to falsify our hypotheses, not simply accumulate supporting evidence while ignoring contradictory findings.

### **Absence of Controls for Confounding Variables**
• Educational research rarely accounts for the multitude of variables that could explain observed outcomes. System-level factors, individual characteristics, family influences, and measurement artifacts are often ignored in favor of simplified explanatory models.

• In R terms, researchers are running models like `outcome ~ single_factor` when the reality requires `outcome ~ factor1 + factor2 + ... + factorN + random_effects`.

### **Lack of Replication Requirements**
• Unlike other scientific disciplines, educational research rarely emphasizes replication of findings across different populations, settings, or time periods. Single studies are used to justify broad policy recommendations without verification.

## Why These Practices Are Damaging

### **Misguided Policy Implementation**
• When research conclusions are based on flawed methodology, resulting policies are likely to be ineffective or harmful. Resources are allocated based on statistical artifacts rather than genuine causal relationships.

• Educational interventions designed around group stereotypes may actively harm individuals whose characteristics don't match their group's statistical profile.

### **Erosion of Scientific Credibility**
• Pseudo-scientific practices undermine public trust in legitimate educational research. When advocacy masquerades as inquiry, it becomes difficult to distinguish evidence-based recommendations from ideological preferences.

• This credibility gap makes it harder to implement genuinely effective educational reforms when they are identified through rigorous research.

### **Missed Opportunities for Genuine Discovery**
• By starting with predetermined conclusions, researchers miss opportunities to discover unexpected relationships or more effective interventions. The focus on confirming existing beliefs prevents the identification of novel solutions to educational challenges.

## Recommendations for Improvement

• **Strengthen research question formulation**: Begin with genuinely open questions about relationships between variables rather than assumed causal pathways.

• **Implement rigorous hypothesis testing**: Require researchers to specify falsifiable hypotheses before data collection and actively seek evidence that could contradict their theories.

• **Control for confounding variables**: Use appropriate statistical techniques to account for the complex, multivariate nature of educational outcomes.

• **Emphasize replication**: Establish standards requiring replication of findings across different contexts before policy implementation.

• **Focus on individual-level analysis**: Develop methodologies that account for individual variation rather than relying solely on group-level statistics.

The stakes in educational research are too high to accept methodological shortcuts. Children's futures depend on evidence-based practices, not statistical artifacts dressed up as scientific findings.
